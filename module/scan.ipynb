{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import easyocr, cv2, os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class Scan:\n",
    "    def __init__(self, oriImg) :\n",
    "        self.oriImg = oriImg\n",
    "\n",
    "\n",
    "    def adjust(self, img):\n",
    "        # # 이미지 전처리 및 외곽선 추출\n",
    "        edged = self.extractEdge(img)\n",
    "        \n",
    "        contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        draw = img.copy()\n",
    "        cv2.drawContours(draw,  contours, -1, (0, 255, 0))\n",
    "        \n",
    "        # 사각형 중 최대크기의 컨투어 꼭지점\n",
    "        pts = self.getPointsOfMaxRectangle(contours)\n",
    "\n",
    "        # 각각의 좌표 찾기\n",
    "        sumXY = pts.sum(axis=1)\n",
    "        diff = np.diff(pts, axis=1)\n",
    "\n",
    "        topLeft = pts[np.argmin(sumXY)]\n",
    "        bottomRight = pts[np.argmax(sumXY)]\n",
    "        topRight = pts[np.argmin(diff)]\n",
    "        bottomLeft = pts[np.argmax(diff)]\n",
    "\n",
    "        # 사진을 변환할 때 사용할 서류의 높이\n",
    "        widthTop = abs(topRight[0] - topLeft[0])\n",
    "        widthBottom = abs(bottomRight[0] - bottomLeft[0])\n",
    "        heightRight = abs(topRight[1] - bottomRight[1])\n",
    "        heightLeft = abs(topLeft[1] - bottomLeft[1])\n",
    "        print(widthBottom, widthTop, heightLeft, heightRight)\n",
    "\n",
    "        width = max([widthTop, widthBottom])\n",
    "        height = max([heightRight, heightLeft])\n",
    "\n",
    "        pts1 = np.float32([topLeft, topRight, bottomRight, bottomLeft])\n",
    "        pts2 = np.float32([[0,0], [width, 0], [width, height], [0, height]])\n",
    "\n",
    "        matrix = cv2.getPerspectiveTransform(pts1, pts2) # 좌표를 변환하기 위해 사용할 변환행렬\n",
    "        result = cv2.warpPerspective(img, matrix, (width, height)) # 이미지 변환(변환행렬 적용)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def extractEdge(self, img):\n",
    "        # 이미지 전처리 및 외곽선 추출\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (3, 3), 0) # 이미지를 흐리게 처리함 (noise 제거를 위해 사용)\n",
    "        edged = cv2.Canny(gray, 75, 250) # edged를 검출하는 함수 (img, minVal, maxVal)\n",
    "        return edged\n",
    "    \n",
    "    def getPointsOfMaxRectangle(self, contours) :\n",
    "        # 크기순으로 컨투어 정렬\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    "        for c in contours:\n",
    "            peri = cv2.arcLength(c, True) # 외곽선 길이\n",
    "            # print(peri)\n",
    "            verticles = cv2.approxPolyDP(c, 0.02 * peri, closed=True) # 외곽선 근사화\n",
    "            if len(verticles) == 4 : \n",
    "                break\n",
    "        pts = verticles.reshape(4, 2) # 배열을 4 * 2 크기로 조정\n",
    "        return pts\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2350 1945 2976 2965\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"./../dataset/KakaoTalk_20240420_113433452_03.jpg\")\n",
    "scanner = Scan(img)\n",
    "\n",
    "result = scanner.adjust(img)\n",
    "\n",
    "cv2.imshow(\"result\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class Ocr:\n",
    "    def getTextBoxes(self, img) : \n",
    "        contourList = []\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        # Morphology Transform - 1차\n",
    "        kernel  = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        grad = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)\n",
    "        # Morphology Transform - 2차\n",
    "        _, bw = cv2.threshold(grad, 0.0, 255.0, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (15,3))\n",
    "        connected = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, kernel2)\n",
    "        cv2.namedWindow(\"connected\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"connected\", connected)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        # contour 찾기\n",
    "        contours, hierarchy = cv2.findContours(connected.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        mask = np.zeros(bw.shape, dtype=np.uint8)\n",
    "        rgb = img.copy()\n",
    "        for idx in range(len(contours)):\n",
    "            x, y, w, h = cv2.boundingRect(contours[idx])\n",
    "            mask[y:y+h, x:x+w] = 0\n",
    "            cv2.drawContours(mask, contours, idx, (255, 255, 255), -1)\n",
    "            r = float(cv2.countNonZero(mask[y:y+h, x:x+w])) / (w*h)\n",
    "            # print(str(cv2.countNonZero(mask[y:y+h, x:x+w])) + \" / \" + str(w*h))\n",
    "            if r > 0.01 and w > 8 and h > 8 :\n",
    "                cv2.rectangle(rgb, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                contourList.append(contours[idx])\n",
    "        # cv2.imshow(\"result\", rgb)\n",
    "        return (rgb, contourList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "ocr = Ocr()\n",
    "_, list = ocr.getTextBoxes(result)\n",
    "# print(list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"img\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"img\", _)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 1994\n",
      "82 119\n",
      "156 199\n",
      "162 190\n",
      "167 197\n",
      "169 198\n",
      "173 210\n",
      "174 211\n",
      "201 235\n",
      "204 244\n"
     ]
    }
   ],
   "source": [
    "# y축 기준으로 정렬하기\n",
    "sortedContours = sorted(list, key=lambda y: cv2.boundingRect(y)[1], reverse=False)\n",
    "# print(a)\n",
    "# print(_.shape)\n",
    "tmp = []\n",
    "draw = _.copy()\n",
    "for i in range(10):\n",
    "    x, y, w, h = cv2.boundingRect(sortedContours[i])\n",
    "    print(y, y+h)\n",
    "    # if r > 0.01 and w > 8 and h > 8 :\n",
    "    cv2.rectangle(draw, (x,y), (x+w, y+h), (255, 255, 0), 2)\n",
    "# cv2.drawContours(draw,  contours, -1, (255, 0, 255), 2)\n",
    "cv2.namedWindow(\"ddd\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"ddd\", draw)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "# boundingRect의 평균높이 구하기\n",
    "arrHeight = []\n",
    "for el in sortedContours:\n",
    "    arrHeight.append(cv2.boundingRect(el)[3])\n",
    "meanHeight = np.mean(arrHeight) +0\n",
    "\n",
    "# contour 반으로 나눠보자\n",
    "leftList = []\n",
    "rightList = []\n",
    "halfOfWidth = _.shape[1] / 2\n",
    "for el in sortedContours:\n",
    "    if (cv2.boundingRect(el)[0] < halfOfWidth) :\n",
    "        leftList.append(el)\n",
    "    else:\n",
    "        rightList.append(el)\n",
    "\n",
    "targetList = rightList\n",
    "targetList = leftList\n",
    "draw = _.copy()\n",
    "isStart = False\n",
    "prev = cv2.boundingRect(targetList[1])   # 일단 예외처리 (2번째까지는 생략)\n",
    "\n",
    "minX = prev[0]\n",
    "minY = prev[1]\n",
    "maxX = prev[0] + prev[2]\n",
    "maxY = prev[1] + prev[3]\n",
    "textArea = []\n",
    "for i in range(len(targetList)):\n",
    "    if (i<=0) :     # 일단 예외처리 (2번째까지는 생략)\n",
    "        continue\n",
    "    if (isStart) :\n",
    "        prev = cv2.boundingRect(targetList[i])\n",
    "        minX = prev[0]\n",
    "        minY = prev[1]\n",
    "        maxX = prev[0] + prev[2]\n",
    "        maxY = prev[1] + prev[3]\n",
    "        isStart = False\n",
    "    x, y, w, h = cv2.boundingRect(targetList[i])\n",
    "    prevHeight = prev[1] + prev[3]\n",
    "    margin = maxY + meanHeight\n",
    "    if(y > margin) :\n",
    "        textArea.append((minX, minY, maxX, maxY))\n",
    "        isStart = True\n",
    "    minX = min(minX, x)\n",
    "    minY = min(minY, y)\n",
    "    maxX = max(maxX, x+w)\n",
    "    maxY = max(maxY, y+h)\n",
    "    prev = cv2.boundingRect(targetList[i])\n",
    "textArea.append((minX, minY, maxX, maxY))\n",
    "\n",
    "# 영역이 잘 찾아진건지 확인\n",
    "for el in textArea:\n",
    "    cv2.rectangle(draw, (el[0], el[1]), (el[2], el[3]), (111, 111, 111), 10)\n",
    "\n",
    "# 마진값 확인\n",
    "cv2.rectangle(draw, (10, 10), (10 + int(meanHeight), 10+ int(meanHeight)), (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"ddd\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"ddd\", draw)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-5, -6], [997, -6], [997, 320], [-5, 320]], '(hat using our value for gp and the values they provide for the opacities (logto(KIR) = -2.99 and log1o(y) = -1.92), setting Tint = 50o K and Teq 1135 K in the petitRADTRANS pa rameterization closely reproduces the T-p profile shown in thei manuscript (Spake et al. 2021, Fig: 11 top panel). Table 1  Summary of the system parameters for the WASP-127 systen used in this manuscript.'], [[[20, 367], [994, 367], [994, 1158], [20, 1158]], 'Adopted parameter Value Planet radius Rp (RJup) 1,.311 +0.025 Planet mass Mp (Mjup) 1.64706 0214 ~-0.0172 Stellar radius Rs (Ro) 1.33+04 025 -0.029 Stellar mass Ms (Mo) 0.9490.0319 Orbital period Porb (days) 4.178062030 000oo008s3 Orbital inclination i (0) 87.84+036 -0.33 a/Rs 7.81+0.4J -0.09 Time of mid-transit To (BJDTBD) 2456776.62124+0.00028 Systemic velocity Vsys (km s-1) -8.25 Stellar radial velocity semi- 0.022+0.002 amplitude Ks (km s-1) References: All listed parameters have been adopted from Seidel et a (2020)'], [[[23, 1257], [997, 1257], [997, 2263], [23, 2263]], '4.1.2. Atmospheric absorbers For   the abundances we used the poor_mans_nonequ_cher subpackage of petitRADTRANS that allowed us to interpolate pressure-dependent chemical abundances for each species basec on input T-p profile, the CIO ratio, and metallicity [Fe/H] Thi function uses a chemical grid calculated with eaSyCHEM (Mol liere et al. 2017). We focused on the strongest absorbers expected in this wave length range, i.e. water (HzO)  carbon monoxide (CO), methane (CH4) , and carbon dioxide (CO2). In a first step, we calculatec separate spectra for each species, with each model only contain ing the absorption lines of one molecule: Since we found no signals for CH4 and COz but significant CCF signals for both HzO and CO; we then also calculated a mode containing lines of both detected species simultaneously: A lis of the used opacity information and the corresponding literature references can be found in Table 2. Furthermore, we explored the option of the inclusion of a clouc deck or haze. We find that a cloud layer; modelled as a grey absorber at an atmospheric pressure of log1o(Pc/bar) = -3 bai has a comparable effect on the shape of the model spectra to that of any additional haze layer with the parameters proposed from retrievals of low-resolution data (Spake et al. 2021). We do not include a haze into our models, because the effects of both absorbers are interchangeable, when only investigating a shor wavelength range like in our case.'], [[[10, 2317], [997, 2317], [997, 2460], [10, 2460]], '4.1.3. Model resolution and normalization Before we applied the cross-correlation of the models with the data, the models were normalized and brought to the spectral']]\n"
     ]
    }
   ],
   "source": [
    "# OCR 확인\n",
    "reader = easyocr.Reader(['en'])\n",
    "el = textArea[0]\n",
    "res = reader.readtext(result[el[1]: el[3], el[0]:el[2]], paragraph=True)\n",
    "\n",
    "print(res)\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"ddd\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"ddd\", result[el[1]: el[3], el[0]:el[2]])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 이미지 전처리 및 외곽선 추출\n",
    "gray = cv2.cvtColor(_, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (3, 3), 0) # 이미지를 흐리게 처리함 (noise 제거를 위해 사용)\n",
    "edged = cv2.Canny(gray, 75, 250) # edged를 검출하는 함수 (img, minVal, maxVal)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "draw = _.copy()\n",
    "cv2.drawContours(draw,  contours, -1, (255, 0, 255), 2)\n",
    "cv2.imshow(\"ddd\", draw)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
