{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr, cv2, os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scan:\n",
    "    def __init__(self, oriImg) :\n",
    "        self.oriImg = oriImg\n",
    "\n",
    "\n",
    "    def adjust(self, img):\n",
    "        # # 이미지 전처리 및 외곽선 추출\n",
    "        edged = self.extractEdge(img)\n",
    "        \n",
    "        contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        draw = img.copy()\n",
    "        cv2.drawContours(draw,  contours, -1, (0, 255, 0))\n",
    "        \n",
    "        # 사각형 중 최대크기의 컨투어 꼭지점\n",
    "        pts = self.getPointsOfMaxRectangle(contours)\n",
    "\n",
    "        # 각각의 좌표 찾기\n",
    "        sumXY = pts.sum(axis=1)\n",
    "        diff = np.diff(pts, axis=1)\n",
    "\n",
    "        topLeft = pts[np.argmin(sumXY)]\n",
    "        bottomRight = pts[np.argmax(sumXY)]\n",
    "        topRight = pts[np.argmin(diff)]\n",
    "        bottomLeft = pts[np.argmax(diff)]\n",
    "\n",
    "        # 사진을 변환할 때 사용할 서류의 높이\n",
    "        widthTop = abs(topRight[0] - topLeft[0])\n",
    "        widthBottom = abs(bottomRight[0] - bottomLeft[0])\n",
    "        heightRight = abs(topRight[1] - bottomRight[1])\n",
    "        heightLeft = abs(topLeft[1] - bottomLeft[1])\n",
    "        print(widthBottom, widthTop, heightLeft, heightRight)\n",
    "\n",
    "        width = max([widthTop, widthBottom])\n",
    "        height = max([heightRight, heightLeft])\n",
    "\n",
    "        pts1 = np.float32([topLeft, topRight, bottomRight, bottomLeft])\n",
    "        pts2 = np.float32([[0,0], [width, 0], [width, height], [0, height]])\n",
    "\n",
    "        matrix = cv2.getPerspectiveTransform(pts1, pts2) # 좌표를 변환하기 위해 사용할 변환행렬\n",
    "        result = cv2.warpPerspective(img, matrix, (width, height)) # 이미지 변환(변환행렬 적용)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def extractEdge(self, img):\n",
    "        # 이미지 전처리 및 외곽선 추출\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (3, 3), 0) # 이미지를 흐리게 처리함 (noise 제거를 위해 사용)\n",
    "        edged = cv2.Canny(gray, 75, 250) # edged를 검출하는 함수 (img, minVal, maxVal)\n",
    "        return edged\n",
    "    \n",
    "    def getPointsOfMaxRectangle(self, contours) :\n",
    "        # 크기순으로 컨투어 정렬\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    "        for c in contours:\n",
    "            peri = cv2.arcLength(c, True) # 외곽선 길이\n",
    "            # print(peri)\n",
    "            verticles = cv2.approxPolyDP(c, 0.02 * peri, closed=True) # 외곽선 근사화\n",
    "            if len(verticles) == 4 : \n",
    "                break\n",
    "        pts = verticles.reshape(4, 2) # 배열을 4 * 2 크기로 조정\n",
    "        return pts\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317 1969 2939 3018\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"./../dataset/KakaoTalk_20240420_113433452_01.jpg\")\n",
    "scanner = Scan(img)\n",
    "\n",
    "result = scanner.adjust(img)\n",
    "\n",
    "cv2.imshow(\"result\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ocr:\n",
    "    def getTextBoxes(self, img) : \n",
    "        contourList = []\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        # Morphology Transform - 1차\n",
    "        kernel  = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        grad = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)\n",
    "        # Morphology Transform - 2차\n",
    "        _, bw = cv2.threshold(grad, 0.0, 255.0, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (15,3))\n",
    "        connected = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, kernel2)\n",
    "        cv2.namedWindow(\"connected\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"connected\", connected)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        # contour 찾기\n",
    "        contours, hierarchy = cv2.findContours(connected.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        mask = np.zeros(bw.shape, dtype=np.uint8)\n",
    "        rgb = img.copy()\n",
    "        for idx in range(len(contours)):\n",
    "            x, y, w, h = cv2.boundingRect(contours[idx])\n",
    "            mask[y:y+h, x:x+w] = 0\n",
    "            cv2.drawContours(mask, contours, idx, (255, 255, 255), -1)\n",
    "            r = float(cv2.countNonZero(mask[y:y+h, x:x+w])) / (w*h)\n",
    "            # print(str(cv2.countNonZero(mask[y:y+h, x:x+w])) + \" / \" + str(w*h))\n",
    "            if r > 0.01 and w > 8 and h > 8 :\n",
    "                cv2.rectangle(rgb, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                contourList.append(contours[idx])\n",
    "        # cv2.imshow(\"result\", rgb)\n",
    "        return (rgb, contourList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr = Ocr()\n",
    "_, list = ocr.getTextBoxes(result)\n",
    "# print(list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"img\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"img\", _)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 112\n",
      "91 1837\n",
      "154 205\n",
      "163 195\n",
      "166 208\n",
      "169 204\n",
      "194 242\n",
      "203 248\n",
      "209 247\n",
      "237 285\n"
     ]
    }
   ],
   "source": [
    "# y축 기준으로 정렬하기\n",
    "sortedContours = sorted(list, key=lambda y: cv2.boundingRect(y)[1], reverse=False)\n",
    "# print(a)\n",
    "# print(_.shape)\n",
    "tmp = []\n",
    "draw = _.copy()\n",
    "for i in range(10):\n",
    "    x, y, w, h = cv2.boundingRect(sortedContours[i])\n",
    "    print(y, y+h)\n",
    "    # if r > 0.01 and w > 8 and h > 8 :\n",
    "    cv2.rectangle(draw, (x,y), (x+w, y+h), (255, 255, 0), 2)\n",
    "# cv2.drawContours(draw,  contours, -1, (255, 0, 255), 2)\n",
    "cv2.namedWindow(\"ddd\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"ddd\", draw)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# boundingRect의 평균높이 구하기\n",
    "arrHeight = []\n",
    "for el in sortedContours:\n",
    "    arrHeight.append(cv2.boundingRect(el)[3])\n",
    "meanHeight = np.mean(arrHeight) +0\n",
    "\n",
    "# contour 반으로 나눠보자\n",
    "leftList = []\n",
    "rightList = []\n",
    "halfOfWidth = _.shape[1] / 2\n",
    "for el in sortedContours:\n",
    "    if (cv2.boundingRect(el)[0] < halfOfWidth) :\n",
    "        leftList.append(el)\n",
    "    else:\n",
    "        rightList.append(el)\n",
    "\n",
    "targetList = rightList\n",
    "targetList = leftList\n",
    "draw = _.copy()\n",
    "isStart = False\n",
    "prev = cv2.boundingRect(targetList[1])   # 일단 예외처리 (2번째까지는 생략)\n",
    "\n",
    "minX = prev[0]\n",
    "minY = prev[1]\n",
    "maxX = prev[0] + prev[2]\n",
    "maxY = prev[1] + prev[3]\n",
    "textArea = []\n",
    "for i in range(len(targetList)):\n",
    "    if (i<=0) :     # 일단 예외처리 (2번째까지는 생략)\n",
    "        continue\n",
    "    if (isStart) :\n",
    "        prev = cv2.boundingRect(targetList[i])\n",
    "        minX = prev[0]\n",
    "        minY = prev[1]\n",
    "        maxX = prev[0] + prev[2]\n",
    "        maxY = prev[1] + prev[3]\n",
    "        isStart = False\n",
    "    x, y, w, h = cv2.boundingRect(targetList[i])\n",
    "    prevHeight = prev[1] + prev[3]\n",
    "    margin = maxY + meanHeight\n",
    "    if(y > margin) :\n",
    "        textArea.append((minX, minY, maxX, maxY))\n",
    "        isStart = True\n",
    "    minX = min(minX, x)\n",
    "    minY = min(minY, y)\n",
    "    maxX = max(maxX, x+w)\n",
    "    maxY = max(maxY, y+h)\n",
    "    prev = cv2.boundingRect(targetList[i])\n",
    "textArea.append((minX, minY, maxX, maxY))\n",
    "\n",
    "# 영역이 잘 찾아진건지 확인\n",
    "for el in textArea:\n",
    "    cv2.rectangle(draw, (el[0], el[1]), (el[2], el[3]), (111, 111, 111), 10)\n",
    "\n",
    "# 마진값 확인\n",
    "cv2.rectangle(draw, (10, 10), (10 + int(meanHeight), 10+ int(meanHeight)), (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"ddd\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"ddd\", draw)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0, 0], [997, 0], [997, 2492], [0, 2492]], \"resolution. When observing at high-resolution (R ~100 000) the dynamics of the atmospheric material can be measured through Doppler shifts of the the signals caused by their relative mo tions towards the observer (Dang et al. 2018; Ehrenreich et al. 2020) . Using this benefit, high wind speeds from jet streams and dayside-to-nightside winds as well as temperature differ- ences can be deduced from observed line broadening and asym metries (Prinoth et al. 2022; Keles 2021). In previous studies, signals from different parts of the planet atmosphere were of ten observed superimposed on each other and had to be disen- tangled through comparison with models containing combined absorption features of different regions (Gandhi et al. 2022) and comparing differences between ingress and egress lines shapes (Seidel et al. 2023; Louden & Wheatley 2015). One advantage that was used to disentangle signals in the time domain was that very close-in planets with very short orbital periods (~ 1-2 days) undergo significant changes in projected viewing angle between transit ingress and egress (Gandhi et al. 2022; Ehrenreich et al 2020; Seidel et al. 2023; Prinoth et al. 2023). This effect; how ever; becomes progressively less pronounced for planets at larger distances from their host stars, i.e. longer orbital periods Here we studied the transmission spectrum of the hot Jupiter exoplanet WASP-127 b, which orbits its G-type host star O a 4.18 day orbit (Lam et al. 2017) The planet has one of the low est densities ever recorded for an exoplanet (p = 0.07 +0.01pJup Lam et al. 2017) which, in combination with its favorable star planet radius ratio, makes it a prime target for atmospheric stud- ies. The first indication of a feature-rich transmission spectrum on this planet was obtained at low resolution with the Andalu- cia Faint Object Spectrograph and Camera (ALFOSC) mounted on the 2.Sm Nordic Optical Telescope (NOT) at ORM obser vatory (Palle et al. 2017). These findings were later confirmed with higher precision using the OSIRIS instrument at the 1Om- GranTeCan (Chen et al. 2018), showing not only sodium and potassium absorption but also a tentative detection of lithium in the planet However; follow-up studies of the planet at high res- olution in the optical wavelength range only measured a weak signal for sodium with ESPRESSO at the 8m-VLT (Allart et al 2020) and HARPS (Seidel et al. 2020), the latter being compati ble with a non-detection. Using the Rossiter-McLaughlin effect, these high-resolution observations of the planet during transit Ie - vealed that the planet is orbiting its host on a misaligned orbit (Allart et al. 2020; Cristo et al. 2022). The atmosphere and Or- bit were further constrained by successful eclipse measurements with Spitzer; which  determined the_planet's  dayside tempera- ture as T ~ 1400 K (1454+43 K, 1373+40 ~41 K at at 3.6 pm and 4.5 pm, respectively; Wallack et al. 2021). Low-resolution space- based spectroscopy obtained in the H band with the WFC3 o the Hubble Space telescope (HST) led to a detection of water in the planet'$ transmission spectrum (Skaf et al. 2020; Spake et al. 2021). An atmospheric retrieval study combining the HST and Spitzer transit data led to conflicting carbon-to-oxygen ratios (CjO) depending on whether chemical equilibrium Or free chem- istry assumptions were adopted (leading to values of C/O ~ 0.8 and CJO ~ 0.0 respectively; Spake et al. 2021). This degener- acy was seemingly solved through recent high-resolution ob- servations of this target over a large wavelength range in the near-infrared 980 2500 nm; using the SPIRou spectrograph, which yielded a detection of water (HzO) and hydroxyl (OH) but no carbon monoxide (CO): The non-detection of CO led to strong upper limits on the CO abundance (log1o(CO) ~4.0) and favored a disequilibrium case with a low CIO ratio for this planet in the joint retrieval of SPIRou + HST + Spitzer data (Boucher et al. 2023). The HzO and OH signals found in this\"]]\n"
     ]
    }
   ],
   "source": [
    "# OCR 확인\n",
    "reader = easyocr.Reader(['en'])\n",
    "el = textArea[0]\n",
    "res = reader.readtext(result[el[1]: el[3], el[0]:el[2]], paragraph=True)\n",
    "\n",
    "print(res)\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"ddd\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"ddd\", result[el[1]: el[3], el[0]:el[2]])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 이미지 전처리 및 외곽선 추출\n",
    "gray = cv2.cvtColor(_, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (3, 3), 0) # 이미지를 흐리게 처리함 (noise 제거를 위해 사용)\n",
    "edged = cv2.Canny(gray, 75, 250) # edged를 검출하는 함수 (img, minVal, maxVal)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "draw = _.copy()\n",
    "cv2.drawContours(draw,  contours, -1, (255, 0, 255), 2)\n",
    "cv2.imshow(\"ddd\", draw)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
